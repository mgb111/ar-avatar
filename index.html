<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
<title>AI Avatar Lip-Sync & AR - Enhanced</title>
<script src="https://cdn.tailwindcss.com"></script>
<style>
    body { font-family: 'Inter', sans-serif; margin:0; overflow:hidden; background-color:#111827; color:#f3f4f6; }
    canvas { display:block; width:100%; height:100%; }
    #ar-button-container { position:absolute; top:0; left:0; right:0; bottom:0; display:flex; justify-content:center; align-items:center; z-index:20; }
    #ar-button { background-color: rgba(31,41,55,0.8); color:white; padding:1rem 2rem; font-size:1.25rem; border-radius:9999px; border:1px solid rgba(75,85,99,0.8); cursor:pointer; font-weight:600; box-shadow:0 4px 6px rgba(0,0,0,0.1); transition: all 0.2s; }
    #ar-button:hover { background-color: rgba(55,65,81,0.9); }
    #loading-overlay, #ar-instructions { position:absolute; top:0; left:0; width:100%; height:100%; display:flex; flex-direction:column; justify-content:center; align-items:center; z-index:100; color:#d1d5db; font-size:1.125rem; background-color: rgba(17,24,39,0.9); text-align:center; padding:1rem; }
    #ar-instructions { display:none; }
    #status-message { position:absolute; top:2rem; left:50%; transform:translateX(-50%); background-color: rgba(239,68,68,0.8); color:white; padding:0.5rem 1rem; border-radius:0.5rem; z-index:110; font-size:0.875rem; display:none; text-align:center; }
    /* debug panel removed */
    .loader, .thinking-loader { border:4px solid #4b5563; border-top:4px solid #60a5fa; border-radius:50%; width:40px; height:40px; animation:spin 1s linear infinite; }
    .loader { margin-bottom:1rem; }
    @keyframes spin { 0%{transform:rotate(0deg);} 100%{transform:rotate(360deg);} }
    #mic-level { width:60px; height:10px; background:#374151; border-radius:5px; overflow:hidden; margin-top:4px; }
    #mic-level-fill { width:0%; height:100%; background:#10b981; transition:width 0.05s; }
</style>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap" rel="stylesheet">
</head>
<body>

<div id="loading-overlay">
    <div class="loader"></div>
    <span>Loading 3D environment...</span>
</div>

<div id="ar-instructions">
    <span>Move your phone to find a flat surface, then tap to place the avatar.</span>
</div>

<div id="status-message"></div>

<div id="ar-button-container">
    <button id="ar-button-placeholder">Enter Augmented Reality</button>
</div>

<div id="ar-controls-container" style="position:absolute; bottom:2rem; left:50%; transform:translateX(-50%); z-index:10; display:none; flex-direction:column; align-items:center; gap:0.5rem;">
    <button id="mic-button" class="w-16 h-16 bg-blue-600 hover:bg-blue-700 text-white font-bold p-4 rounded-full transition duration-200 shadow-lg flex justify-center items-center">
        <svg id="mic-icon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M12 1a3 3 0 0 0-3 3v8a3 3 0 0 0 6 0V4a3 3 0 0 0-3-3z"></path><path d="M19 10v2a7 7 0 0 1-14 0v-2"></path><line x1="12" y1="19" x2="12" y2="23"></line></svg>
        <div id="thinking-icon" class="thinking-loader" style="display:none; width:24px; height:24px;"></div>
    </button>
    <div id="mic-level"><div id="mic-level-fill"></div></div>
    <!-- Text input fallback -->
    <div style="display:flex; gap:0.5rem; width:90vw; max-width:520px;">
        <input id="text-input" type="text" placeholder="Type your prompt..." class="flex-1 px-3 py-2 rounded-md bg-gray-800 text-gray-100 border border-gray-600 focus:outline-none focus:ring-2 focus:ring-blue-500" />
        <button id="send-button" class="px-4 py-2 rounded-md bg-green-600 hover:bg-green-700 text-white font-semibold">Send</button>
    </div>
</div>

<script async src="https://unpkg.com/es-module-shims@1.8.0/dist/es-module-shims.js"></script>
<script type="importmap">
{
    "imports": {
        "three": "https://cdn.jsdelivr.net/npm/three@0.160.0/build/three.module.js",
        "three/addons/": "https://cdn.jsdelivr.net/npm/three@0.160.0/examples/jsm/"
    }
}
</script>

<script type="module">
import * as THREE from 'three';
import { GLTFLoader } from 'three/addons/loaders/GLTFLoader.js';
import { OrbitControls } from 'three/addons/controls/OrbitControls.js';
import { ARButton } from 'three/addons/webxr/ARButton.js';

// Backend proxy base URL (host your Node backend on Vercel/Render/Railway/Fly)
// Example: https://your-backend.example.com
const BACKEND_URL = 'https://ar-avatar.vercel.app';

let camera, scene, renderer, controls, model, mixer, clock, jawOpenMorphTargetIndex = null, jawMesh = null, jawBone = null, jawBoneBaseX = 0, lastJaw=0;
let reticle, speechRecognition, isListening=false, isSpeaking=false, isAIThinking=false, currentAudio=null, audioContext, analyser, dataArray;
let hitTestSource=null, hitTestSourceRequested=false, groundPlane=null;
let isPlaced=false, allowReposition=false, longPressTimer=null, longPressStart={x:0,y:0};
const LONG_PRESS_MS=600, MOVE_TOLERANCE=10; // px
let audioSource, activeGesture=null, initialScale=new THREE.Vector3(), initialPinchDistance=0;

const loadingOverlay=document.getElementById('loading-overlay');
const arButtonContainer=document.getElementById('ar-button-container');
const arInstructions=document.getElementById('ar-instructions');
const statusMessage=document.getElementById('status-message');
const arControlsContainer=document.getElementById('ar-controls-container');
const micButton=document.getElementById('mic-button');
const micIcon=document.getElementById('mic-icon');
const thinkingIcon=document.getElementById('thinking-icon');
const micLevelFill=document.getElementById('mic-level-fill');
const textInput=document.getElementById('text-input');
const sendButton=document.getElementById('send-button');

// debug elements removed

const defaultAvatarUrl='https://raw.githubusercontent.com/mgb111/ar-avatar/main/avatar.glb';
const aiQueue=[];

init();

function init(){
    // Backend URL check (silent)
    if(!BACKEND_URL){ /* no-op */ }

    scene=new THREE.Scene();
    clock=new THREE.Clock();
    camera=new THREE.PerspectiveCamera(75,window.innerWidth/window.innerHeight,0.1,1000);
    camera.position.set(0,1.6,2.5);

    // Audio context
    try{ audioContext=new (window.AudioContext||window.webkitAudioContext)(); } catch(e){ /* no-op */ }

    // WebXR Support
    if('xr' in navigator){ navigator.xr.isSessionSupported('immersive-ar').then(()=>{}); }

    const ambientLight=new THREE.AmbientLight(0xffffff,1.5); scene.add(ambientLight);
    const directionalLight=new THREE.DirectionalLight(0xffffff,2.5); directionalLight.position.set(1,1,1); scene.add(directionalLight);

    renderer=new THREE.WebGLRenderer({ antialias:true, alpha:true });
    renderer.setSize(window.innerWidth,window.innerHeight);
    renderer.setPixelRatio(window.devicePixelRatio);
    renderer.xr.enabled=true;
    document.body.appendChild(renderer.domElement);

    controls=new OrbitControls(camera,renderer.domElement);
    controls.target.set(0,1,0);
    controls.update();

    loadModel(defaultAvatarUrl);
    setupSpeechRecognition();
    setupAR();

    micButton.addEventListener('click',toggleListening);
    if(sendButton){
        const sendText=()=>{ const v=textInput?.value?.trim(); if(!v||isSpeaking||isAIThinking) return; queueAI(v); textInput.value=''; };
        sendButton.addEventListener('click',sendText);
        textInput?.addEventListener('keydown',(e)=>{ if(e.key==='Enter'){ e.preventDefault(); sendText(); }});
    }

    window.addEventListener('resize',onWindowResize);
    renderer.domElement.addEventListener('touchstart',onTouchStart,{passive:false});
    renderer.domElement.addEventListener('touchmove',onTouchMove,{passive:false});
    renderer.domElement.addEventListener('touchend',onTouchEnd);

    renderer.setAnimationLoop(animate);
}

// --- Functions --- //

function showStatusMessage(message,isError=true){
    statusMessage.textContent=message;
    statusMessage.style.backgroundColor=isError?'rgba(239,68,68,0.8)':'rgba(34,197,94,0.8)';
    statusMessage.style.display='block';
    setTimeout(()=>{statusMessage.style.display='none';},5000);
}

// --- AR Button --- //
function setupAR(){
    const arButton=ARButton.createButton(renderer,{ requiredFeatures:['hit-test','dom-overlay'], domOverlay:{root:document.body} });
    arButton.id='ar-button';
    arButton.textContent="Enter Augmented Reality";
    arButton.addEventListener('click',()=>{ if(audioContext.state==='suspended') audioContext.resume(); });
    renderer.xr.addEventListener('sessionstart',()=>{
        arButtonContainer.style.display='none';
        arInstructions.style.display='flex';
        controls.enabled=false;
        arControlsContainer.style.display='flex';
    });
    renderer.xr.addEventListener('sessionend',()=>{
        arButtonContainer.style.display='flex';
        arControlsContainer.style.display='none';
        arInstructions.style.display='none';
        if(currentAudio) currentAudio.pause();
        controls.enabled=true;
        if(model){ model.position.set(0,0,0); model.visible=true; }
    });
    arButtonContainer.innerHTML=''; arButtonContainer.appendChild(arButton);

    reticle=new THREE.Mesh(
        new THREE.RingGeometry(0.05,0.07,32).rotateX(-Math.PI/2),
        new THREE.MeshBasicMaterial()
    );
    reticle.matrixAutoUpdate=false;
    reticle.visible=false;
    scene.add(reticle);

    let controller=renderer.xr.getController(0);
    controller.addEventListener('select',onSelect);
    scene.add(controller);
}

// --- Speech Recognition --- //
function setupSpeechRecognition(){
    const SpeechRecognition=window.SpeechRecognition||window.webkitSpeechRecognition;
    if(SpeechRecognition){
        speechRecognition=new SpeechRecognition();
        // Android Chrome works better with interimResults and sometimes continuous
        speechRecognition.continuous=true;
        speechRecognition.lang=navigator.language||'en-US';
        speechRecognition.interimResults=true;
        speechRecognition.maxAlternatives=1;

        speechRecognition.onresult=(event)=>{
            // Build the full transcript including interim results
            let interim=''; let final='';
            for(let i=event.resultIndex;i<event.results.length;i++){
                const res=event.results[i];
                if(res.isFinal) queueAI(res[0].transcript.trim());
            }
        };
        speechRecognition.onstart=()=>{ isListening=true; micButton.classList.add('bg-red-600','hover:bg-red-700'); micButton.classList.remove('bg-blue-600','hover:bg-blue-700'); };
        speechRecognition.onend=()=>{ isListening=false; micButton.classList.remove('bg-red-600','hover:bg-red-700'); micButton.classList.add('bg-blue-600','hover:bg-blue-700'); };
        speechRecognition.onaudiostart=()=>{};
        speechRecognition.onaudioend=()=>{ /* often fires quickly on Android */ };
        speechRecognition.onspeechstart=()=>{};
        speechRecognition.onspeechend=()=>{ /* recognition will finalize shortly */ };
        // Single auto-retry on no match (some Android builds require a quick restart)
        let didRetryNoMatch=false;
        speechRecognition.onnomatch=()=>{
            if(!didRetryNoMatch){
                didRetryNoMatch=true;
                try{ speechRecognition.abort(); }catch{}
                setTimeout(()=>{ try{ speechRecognition.start(); }catch{} }, 200);
            } else {
                showStatusMessage('Did not catch that. Please try again.', false);
            }
        };
        speechRecognition.onerror=(event)=>{
            let hint='';
            if(event.error==='not-allowed' || event.error==='denied') hint='Please allow microphone access in your browser settings.';
            if(event.error==='no-speech') hint='No speech detected. Try speaking closer to the mic.';
            if(event.error==='aborted') hint='Recognition aborted. Tap the mic again.';
            showStatusMessage(`Microphone error: ${event.error}. ${hint}`);
        };
        // Reset retry flag when session ends
        speechRecognition.onend=(()=>{
            const origEnd = speechRecognition.onend;
            return ()=>{
                didRetryNoMatch=false;
                isListening=false; micButton.classList.remove('bg-red-600','hover:bg-red-700'); micButton.classList.add('bg-blue-600','hover:bg-blue-700');
                if(typeof origEnd==='function') origEnd();
            };
        })();
    } else { 
        micButton.disabled=true; showStatusMessage('Voice input not supported',false); 
    }
}

function toggleListening(){
    if(isListening||isSpeaking||isAIThinking) return;
    if(currentAudio) currentAudio.pause();
    // SpeechRecognition requires secure context (https or localhost)
    const isSecure = location.protocol==='https:' || location.hostname==='localhost';
    if(!isSecure){ showStatusMessage('Voice input requires HTTPS. Please use a secure URL.'); return; }
    if(navigator.mediaDevices?.getUserMedia){
        navigator.mediaDevices.getUserMedia({audio:true}).then(()=>{
            try{ speechRecognition.abort(); }catch{}
            try{ speechRecognition.start(); }catch{ showStatusMessage('Unable to start speech recognition'); }
        }).catch(()=>{ showStatusMessage('Microphone access denied'); });
    } else if(speechRecognition){ speechRecognition.start(); } else { showStatusMessage('Voice input unavailable'); }
}

// --- AI Queue --- //
function queueAI(prompt){ aiQueue.push(prompt); if(!isAIThinking && !isSpeaking) processAIQueue(); }
async function processAIQueue(){
    if(!aiQueue.length) return;
    const prompt=aiQueue.shift();
    await getAIResponse(prompt);
    processAIQueue();
}

// --- OpenAI API --- //
async function getAIResponse(userPrompt){
    isAIThinking=true; micIcon.style.display='none'; thinkingIcon.style.display='block'; micButton.disabled=true; if(sendButton) sendButton.disabled=true; if(textInput) textInput.disabled=true;

    const systemPrompt=`You are a helpful AR avatar assistant. Be concise and conversational.`;

    try{
        if(!BACKEND_URL){ throw new Error('Backend URL not configured'); }
        const response=await fetch(`${BACKEND_URL}/api/chat`,{
            method:'POST',
            headers:{'Content-Type':'application/json'},
            body:JSON.stringify({ systemPrompt, userPrompt })
        });
        if(!response.ok){
            let detail = '';
            const clone = response.clone();
            try { detail = JSON.stringify(await response.json()); }
            catch { detail = (await clone.text()).slice(0,200); }
            throw new Error(`API error ${response.status}: ${detail}`);
        }
        const data=await response.json();
        const text=data.text||"Sorry, I couldn't generate a response.";
        await generateAndPlaySpeech(text.trim());
    } catch(error){ showStatusMessage(error.message); console.error(error); }
    finally{ isAIThinking=false; micIcon.style.display='block'; thinkingIcon.style.display='none'; micButton.disabled=false; if(sendButton) sendButton.disabled=false; if(textInput) textInput.disabled=false; }
}

// --- TTS + Lip-Sync --- //
async function generateAndPlaySpeech(text){
    if(!text||!model) return;
    isSpeaking=true;

    try{
        if(!BACKEND_URL){ throw new Error('Backend URL not configured'); }
        const response=await fetch(`${BACKEND_URL}/api/tts`,{
            method:'POST',
            headers:{'Content-Type':'application/json'},
            body:JSON.stringify({ text })
        });
        if(!response.ok){
            let detail = '';
            const clone = response.clone();
            try { detail = JSON.stringify(await response.json()); }
            catch { detail = (await clone.text()).slice(0,200); }
            throw new Error(`TTS generation failed (${response.status}): ${detail}`);
        }
        // Clean up any previous playback and nodes
        try{ if(currentAudio){ currentAudio.pause(); currentAudio.src=''; } }catch{}
        try{ if(audioSource){ audioSource.disconnect(); audioSource=null; } }catch{}
        try{ if(analyser){ analyser.disconnect(); analyser=null; } }catch{}

        const blob=await response.blob();
        const audioUrl=URL.createObjectURL(blob);
        const audio=new Audio();
        audio.src = audioUrl;
        audio.preload = 'auto';
        audio.playsInline = true;
        audio.loop=false;
        currentAudio=audio;

        // Build audio graph
        if(audioContext.state==='suspended') { try{ await audioContext.resume(); }catch{} }
        audioSource=audioContext.createMediaElementSource(audio);
        analyser=audioContext.createAnalyser();
        analyser.fftSize=128; // lighter processing to reduce glitches
        dataArray=new Uint8Array(analyser.frequencyBinCount);
        audioSource.connect(analyser).connect(audioContext.destination);

        const startPlayback = async ()=>{
            try{
                await audio.play();
                animateJawSync();
            }catch(e){ console.warn('Playback start failed, trying resume', e); try{ await audioContext.resume(); await audio.play(); }catch(err){ console.error(err); showStatusMessage('Audio playback blocked'); } }
        };
        if(audio.readyState>=3){
            await startPlayback();
        } else {
            audio.addEventListener('canplaythrough', startPlayback, { once:true });
        }

        audio.onended=()=>{
            isSpeaking=false;
            jawOpenMorphTargetIndex!==null && setJaw(0);
            try{ if(audioSource){ audioSource.disconnect(); audioSource=null; } }catch{}
            try{ if(analyser){ analyser.disconnect(); analyser=null; } }catch{}
            try{ URL.revokeObjectURL(audioUrl); }catch{}
        };
    } catch(e){ console.error(e); showStatusMessage('Audio playback error'); isSpeaking=false; }
}

// --- Jaw Lip-Sync --- //
function animateJawSync(){
    if(!analyser || !model) return;
    requestAnimationFrame(animateJawSync);
    analyser.getByteFrequencyData(dataArray);
    const avgAmplitude=dataArray.reduce((a,b)=>a+b,0)/dataArray.length/256;
    setJaw(avgAmplitude*3.5); // stronger movement for visibility
}

function setJaw(value){
    // Smooth value to avoid jitter
    let v = Math.min(Math.max(value,0),1);
    v = lastJaw*0.6 + v*0.4; // smoothing
    lastJaw = v;
    if(jawMesh && jawOpenMorphTargetIndex!==null && jawMesh.morphTargetInfluences){
        jawMesh.morphTargetInfluences[jawOpenMorphTargetIndex]=v;
        return;
    }
    // Fallback: rotate jaw bone around X if available
    if(jawBone){
        // Typical jaw open is rotation downwards (negative X in many rigs). Adjust factor as needed.
        const maxOpen = -0.35; // ~20 degrees
        jawBone.rotation.x = jawBoneBaseX + v * maxOpen;
        if(Math.abs(jawBone.rotation.x-jawBoneBaseX)<0.01){
            jawBone.rotation.y = jawBoneBaseX + v * maxOpen;
            if(Math.abs(jawBone.rotation.y-jawBoneBaseX)<0.01){
                jawBone.rotation.z = jawBoneBaseX + v * maxOpen;
            }
        }
    }
}

// --- Model Loading --- //
function loadModel(url){
    const loader=new GLTFLoader();
    loader.load(url, gltf=>{
        model=gltf.scene; scene.add(model); model.position.set(0,0,0); model.visible=true;
        // Find a suitable morph target for jaw/mouth opening on any mesh
        const candidates=['jawOpen','JawOpen','JAW_Open','MouthOpen','mouthOpen','openMouth','OpenMouth','viseme_aa','AA','Aa','a','A','viseme_A'];
        jawOpenMorphTargetIndex = null; jawMesh = null; jawBone = null; jawBoneBaseX = 0;
        let bestScore = -Infinity, bestMesh = null, bestIndex = null, bestMorphName = '';
        model.traverse(child=>{
            if(!child.isMesh || !child.morphTargetDictionary) return;
            const dict = child.morphTargetDictionary;
            const meshName = (child.name||'').toLowerCase();
            for(const [key, idx] of Object.entries(dict)){
                const k = key.toLowerCase();
                // Base score from morph name
                let score = 0;
                if(candidates.map(n=>n.toLowerCase()).includes(k)) score += 5;
                if(k.includes('jaw')) score += 4;
                if(k.includes('mouth')) score += 3;
                if(k.includes('open')) score += 2;
                if(k.includes('aa') || k==='a') score += 1;
                // Mesh preference
                if(meshName.includes('head')||meshName.includes('face')||meshName.includes('jaw')||meshName.includes('mouth')) score += 3;
                if(meshName.includes('eye')||meshName.includes('eyelid')||meshName.includes('brow')||meshName.includes('teeth')||meshName.includes('tongue')) score -= 5;
                if(score>bestScore){ bestScore=score; bestMesh=child; bestIndex=idx; bestMorphName=key; }
            }
        });
        if(bestMesh && bestScore>0){ jawMesh=bestMesh; jawOpenMorphTargetIndex=bestIndex; }
        // If no morph target found, look for a jaw/mouth bone
        if(jawOpenMorphTargetIndex===null){
            model.traverse(child=>{
                if(jawBone) return;
                if(child.isBone){
                    const n = (child.name||'').toLowerCase();
                    if(n.includes('jaw') || n.includes('chin') || (n.includes('mouth') && !n.includes('upper'))){
                        jawBone = child;
                        jawBoneBaseX = child.rotation.x;
                        
                    }
                }
            });
        }

        // no lip sync UI
        loadingOverlay.style.display='none';
        // Put arms down (adjust common upper-arm bones)
        try{ putArmsDown(); }catch{}
    },xhr=>{},err=>{ loadingOverlay.style.display='none'; showStatusMessage('Failed to load 3D model'); });
}

// --- AR Placement --- //
function onSelect(){
    if(!reticle.visible) return;
    // Only allow first-time placement via tap. Later moves require long-press.
    if(!isPlaced && model){
        model.position.setFromMatrixPosition(reticle.matrix);
        model.visible=true;
        arInstructions.style.display='none';
        reticle.visible=false;
        isPlaced=true;
    }
}

// --- Reset Avatar --- //
function resetAvatar(){ if(model){ model.position.set(0,0,0); model.scale.set(1,1,1); model.rotation.set(0,0,0); jawOpenMorphTargetIndex!==null && setJaw(0); reticle.visible=true; } }

// --- Touch Gestures for Scale --- //
let ongoingTouches=[];
function getDistance(touches){ const dx=touches[0].clientX-touches[1].clientX; const dy=touches[0].clientY-touches[1].clientY; return Math.sqrt(dx*dx+dy*dy); }
function onTouchStart(e){
    // Two-finger pinch to scale
    if(e.touches.length===2 && model){
        initialScale.copy(model.scale); initialPinchDistance=getDistance(e.touches);
        if(longPressTimer){ clearTimeout(longPressTimer); longPressTimer=null; }
        allowReposition=false;
        return;
    }
    // One-finger long-press to enable reposition (only if already placed)
    if(e.touches.length===1 && renderer.xr.isPresenting && isPlaced){
        const t=e.touches[0];
        longPressStart={x:t.clientX,y:t.clientY};
        if(longPressTimer){ clearTimeout(longPressTimer); }
        longPressTimer=setTimeout(()=>{
            allowReposition=true; reticle.visible=true; arInstructions.style.display='flex';
        }, LONG_PRESS_MS);
    }
}
function onTouchMove(e){
    // Cancel long-press if finger moves too much
    if(e.touches.length===1 && longPressTimer){
        const t=e.touches[0];
        if(Math.abs(t.clientX-longPressStart.x)>MOVE_TOLERANCE || Math.abs(t.clientY-longPressStart.y)>MOVE_TOLERANCE){
            clearTimeout(longPressTimer); longPressTimer=null;
        }
    }
    if(e.touches.length===2 && model){
        const newDist=getDistance(e.touches); const scaleFactor=newDist/initialPinchDistance; model.scale.copy(initialScale.clone().multiplyScalar(scaleFactor));
    }
}
function onTouchEnd(e){
    if(longPressTimer){ clearTimeout(longPressTimer); longPressTimer=null; }
    if(e.touches.length<2) initialPinchDistance=0;
    // If long-press enabled reposition and reticle is visible, move model to reticle on release
    if(allowReposition && reticle.visible && model){
        model.position.setFromMatrixPosition(reticle.matrix);
        reticle.visible=false; arInstructions.style.display='none';
        allowReposition=false;
    }
}

// --- Window Resize --- //
function onWindowResize(){ camera.aspect=window.innerWidth/window.innerHeight; camera.updateProjectionMatrix(); renderer.setSize(window.innerWidth,window.innerHeight); }

// --- Animate Loop --- //
function animate(){ const delta=clock.getDelta(); if(mixer) mixer.update(delta); renderer.render(scene,camera); updateARHitTest(); updateMicLevel(); }

function updateARHitTest(){
    if(renderer.xr.isPresenting && !hitTestSourceRequested){
        const session=renderer.xr.getSession();
        session.requestReferenceSpace('viewer').then(refSpace=>{
            session.requestHitTestSource({space:refSpace}).then(source=>{ hitTestSource=source; });
        });
        session.addEventListener('end',()=>{ hitTestSourceRequested=false; hitTestSource=null; });
        hitTestSourceRequested=true;
    }
    if(hitTestSource && renderer.xr.getSession()){
        const frame=renderer.xr.getFrame();
        const referenceSpace=renderer.xr.getReferenceSpace();
        const hitTestResults=frame.getHitTestResults(hitTestSource);
        if(hitTestResults.length>0){
            const pose=hitTestResults[0].getPose(referenceSpace);
            reticle.visible=true;
            reticle.position.set(pose.transform.position.x,pose.transform.position.y,pose.transform.position.z);
            reticle.updateMatrix();
        } else { reticle.visible=false; }
    }
}

// --- Mic Level --- //
function updateMicLevel(){
    if(analyser && isListening){
        analyser.getByteFrequencyData(dataArray);
        const avg=dataArray.reduce((a,b)=>a+b,0)/dataArray.length;
        micLevelFill.style.width=Math.min((avg/128*100),100)+'%';
    } else { micLevelFill.style.width='0%'; }
}
</script>
</body>
</html>
