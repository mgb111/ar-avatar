<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Talking Avatar with HeadTTS</title>
    <style>
        body { 
            font-family: sans-serif;
            margin: 0;
            overflow: hidden; /* Prevent scrollbars */
        }
        #container {
            width: 100vw;
            height: 100vh;
        }
        #controls {
            position: absolute;
            top: 20px;
            left: 20px;
            padding: 10px;
            background: rgba(0,0,0,0.5);
            border-radius: 8px;
            color: white;
        }
        textarea {
            width: 300px;
            height: 60px;
            margin-bottom: 10px;
        }
        button {
            padding: 10px 15px;
            cursor: pointer;
        }
    </style>

    <script type="importmap">
    {
      "imports": {
        "three": "https://cdn.jsdelivr.net/npm/three@0.165.0/build/three.module.js",
        "three/addons/": "https://cdn.jsdelivr.net/npm/three@0.165.0/examples/jsm/",
        "talkinghead": "https://cdn.jsdelivr.net/gh/met4citizen/TalkingHead@1.6/modules/talkinghead.mjs",
        "headtts": "https://cdn.jsdelivr.net/gh/met4citizen/HeadTTS@0.2/modules/headtts.mjs"
      }
    }
    </script>
</head>
<body>
    <div id="container"></div>

    <div id="controls">
        <textarea id="script-input">Hello! I am an Augmented Reality avatar. I can speak any text you write here.</textarea>
        <button id="speak-button">Speak</button>
        <p id="status">Status: Ready</p>
    </div>

    <script type="module">
        import * as THREE from 'three';
        import { OrbitControls } from 'three/addons/controls/OrbitControls.js';
        import { TalkingHead } from 'talkinghead';
        import { HeadTTS } from 'headtts';

        // --- 1. Basic Three.js Scene Setup ---
        const scene = new THREE.Scene();
        scene.background = new THREE.Color(0xeeeeee);
        const camera = new THREE.PerspectiveCamera(50, window.innerWidth / window.innerHeight, 0.1, 1000);
        camera.position.set(0, 1.6, 2.5);

        const renderer = new THREE.WebGLRenderer({ antialias: true });
        renderer.setSize(window.innerWidth, window.innerHeight);
        document.getElementById('container').appendChild(renderer.domElement);

        const controls = new OrbitControls(camera, renderer.domElement);
        controls.target.set(0, 1.4, 0); // Target the head of the avatar
        controls.update();

        // Add some lighting
        const ambientLight = new THREE.AmbientLight(0xffffff, 1.5);
        scene.add(ambientLight);
        const directionalLight = new THREE.DirectionalLight(0xffffff, 2);
        directionalLight.position.set(1, 1, 1);
        scene.add(directionalLight);
        
        const statusElement = document.getElementById('status');
        let head; // To hold the TalkingHead instance
        let headtts; // To hold the HeadTTS instance

        async function initializeAvatar() {
            // --- 2. Initialize TalkingHead ---
            statusElement.innerText = 'Status: Loading Avatar...';
            head = new TalkingHead(scene, {
                camera: camera,
                ttsEndpoint: "none" // We are using HeadTTS, so we disable the default
            });
            // IMPORTANT: Replace 'avatar.glb' with the path to your own model
            await head.loadModel('avatar.glb'); 
            head.setVisible(true);
            statusElement.innerText = 'Status: Avatar Loaded.';
            
            // --- 3. Initialize HeadTTS ---
            statusElement.innerText = 'Status: Loading TTS Engine...';
            headtts = new HeadTTS();
            statusElement.innerText = 'Status: Ready.';

            // --- 4. Connect HeadTTS to TalkingHead ---
            headtts.onmessage = (message) => {
                if (message.type === "audio") {
                    // When HeadTTS produces audio, feed it to the TalkingHead
                    head.speakAudio(message.data);
                } else if (message.type === "error") {
                    console.error("HeadTTS Error:", message.data.error);
                    statusElement.innerText = 'Status: TTS Error.';
                }
            };
        }

        // --- Event Listener for the Button ---
        document.getElementById('speak-button').addEventListener('click', () => {
            if (!head || !headtts) {
                alert('Avatar or TTS not initialized yet.');
                return;
            }
            const text = document.getElementById('script-input').value;
            if (text) {
                statusElement.innerText = 'Status: Synthesizing speech...';
                // This tells HeadTTS to generate the audio and visemes
                headtts.synthesize({ input: text }); 
            }
        });

        // Animation loop to render the scene
        function animate() {
            requestAnimationFrame(animate);
            if (head) head.update(performance.now()); // Update the avatar animations
            renderer.render(scene, camera);
        }

        initializeAvatar();
        animate();
    </script>
</body>
</html>
