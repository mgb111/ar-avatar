<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Talking Avatar working example</title>

  <script type="importmap">
  {
    "imports": {
      "three": "https://cdn.jsdelivr.net/npm/three@0.180.0/build/three.module.js",
      "three/addons/": "https://cdn.jsdelivr.net/npm/three@0.180.0/examples/jsm/",
      "talkinghead": "https://cdn.jsdelivr.net/gh/met4citizen/TalkingHead@1.6.0/modules/talkinghead.mjs",
      "headtts": "https://cdn.jsdelivr.net/npm/@met4citizen/headtts@0.2.1/+esm"
    }
  }
  </script>

  <style>
    body { margin: 0; font-family: system-ui, sans-serif; background: #f3f4f6; }
    #avatar { width: 100vw; height: 100vh; position: relative; overflow: hidden; }
    #controls {
      position: absolute; left: 16px; top: 16px; z-index: 40;
      background: rgba(0,0,0,0.5); color: white; padding: 10px; border-radius: 8px;
    }
    button { padding: 8px 12px; cursor: pointer; }
    p { margin: 8px 0 0 0; font-size: 13px; color: #fff; }
  </style>
</head>
<body>
  <div id="avatar"></div>

  <div id="controls">
    <button id="speak-button">Play Introduction</button>
    <p id="status">Status: Starting</p>
  </div>

  <script type="module">
    import { TalkingHead } from 'talkinghead';
    import { HeadTTS } from 'headtts';

    const nodeAvatar = document.getElementById('avatar');
    const statusEl = document.getElementById('status');
    const speakBtn = document.getElementById('speak-button');

    let head = null;
    let headtts = null;
    const myPredefinedScript = "Hello, this talking avatar is now working correctly.";

    async function initialize() {
      statusEl.innerText = 'Status: Initializing TalkingHead';
      try {
        // Create the TalkingHead instance attached to the DOM node
        // avatarOnly false means TalkingHead creates its own renderer and camera
        head = new TalkingHead(nodeAvatar, {
          ttsEndpoint: "none",
          lipsyncModules: [],        // disable dynamic lip module auto load for now
          lipsyncLang: "en",
          cameraView: "head",
          cameraDistance: 0.9,
          cameraRotateEnable: true
        });

        statusEl.innerText = 'Status: Loading avatar model';

        // Use a known Ready Player Me example model so you can test immediately.
        // Replace the url below with './avatar.glb' or your own URL when you want to test your file.
        await head.showAvatar({
          url: "https://models.readyplayer.me/64bfa15f0e72c63d7c3934a6.glb?morphTargets=ARKit,Oculus+Visemes,mouthOpen,mouthSmile,eyesClosed,eyesLookUp,eyesLookDown&textureSizeLimit=1024&textureFormat=png",
          lipsyncLang: "en"
        });

        head.setVisible(true);
        statusEl.innerText = 'Status: Avatar loaded';

        // Initialize HeadTTS and forward audio to TalkingHead
        headtts = new HeadTTS();

        headtts.onmessage = (message) => {
          if (message.type === "audio") {
            // speakAudio accepts the audio payload produced by HeadTTS
            try { head.speakAudio(message.data); }
            catch (e) { console.error("speakAudio failed", e); }
          } else if (message.type === "error") {
            console.error("HeadTTS error", message.data);
            statusEl.innerText = 'Status: TTS error';
          }
        };

        statusEl.innerText = 'Status: Ready';
      } catch (err) {
        console.error("Initialization error", err);
        statusEl.innerText = "Error: " + (err && err.message ? err.message : String(err));
      }
    }

    speakBtn.addEventListener('click', () => {
      if (!head || !headtts) { alert('Avatar not ready'); return; }
      statusEl.innerText = 'Status: Synthesizing speech';
      // HeadTTS will send audio messages which we forward to head.speakAudio
      headtts.synthesize({ input: myPredefinedScript, lang: "en-US" });
    });

    // Start
    initialize();
  </script>
</body>
</html>
