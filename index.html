<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
<title>AI Avatar Lip-Sync & AR - Enhanced</title>
<script src="https://cdn.tailwindcss.com"></script>
<style>
    body { font-family: 'Inter', sans-serif; margin:0; overflow:hidden; background-color:#111827; color:#f3f4f6; }
    canvas { display:block; width:100%; height:100%; }
    #ar-button-container { position:absolute; top:0; left:0; right:0; bottom:0; display:flex; justify-content:center; align-items:center; z-index:20; }
    #ar-button { background-color: rgba(31,41,55,0.8); color:white; padding:1rem 2rem; font-size:1.25rem; border-radius:9999px; border:1px solid rgba(75,85,99,0.8); cursor:pointer; font-weight:600; box-shadow:0 4px 6px rgba(0,0,0,0.1); transition: all 0.2s; }
    #ar-button:hover { background-color: rgba(55,65,81,0.9); }
    #loading-overlay, #ar-instructions { position:absolute; top:0; left:0; width:100%; height:100%; display:flex; flex-direction:column; justify-content:center; align-items:center; z-index:100; color:#d1d5db; font-size:1.125rem; background-color: rgba(17,24,39,0.9); text-align:center; padding:1rem; }
    #ar-instructions { display:none; }
    #status-message { position:absolute; top:2rem; left:50%; transform:translateX(-50%); background-color: rgba(239,68,68,0.8); color:white; padding:0.5rem 1rem; border-radius:0.5rem; z-index:110; font-size:0.875rem; display:none; text-align:center; }
    #debug-panel { position:absolute; top:1rem; right:1rem; background-color: rgba(0,0,0,0.8); color:white; padding:1rem; border-radius:0.5rem; font-size:0.75rem; z-index:120; max-width:300px; }
    #test-button, #reset-button { background-color:#10b981; color:white; padding:0.5rem 1rem; border-radius:0.5rem; border:none; cursor:pointer; margin-top:0.5rem; }
    .loader, .thinking-loader { border:4px solid #4b5563; border-top:4px solid #60a5fa; border-radius:50%; width:40px; height:40px; animation:spin 1s linear infinite; }
    .loader { margin-bottom:1rem; }
    @keyframes spin { 0%{transform:rotate(0deg);} 100%{transform:rotate(360deg);} }
    #mic-level { width:60px; height:10px; background:#374151; border-radius:5px; overflow:hidden; margin-top:4px; }
    #mic-level-fill { width:0%; height:100%; background:#10b981; transition:width 0.05s; }
</style>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap" rel="stylesheet">
</head>
<body>

<div id="loading-overlay">
    <div class="loader"></div>
    <span>Loading 3D environment...</span>
</div>

<div id="ar-instructions">
    <span>Move your phone to find a flat surface, then tap to place the avatar.</span>
</div>

<div id="status-message"></div>

<div id="debug-panel">
    <div><strong>Debug Info:</strong></div>
    <div id="api-key-status">API Key: Checking...</div>
    <div id="speech-status">Speech Recognition: Checking...</div>
    <div id="audio-status">Audio Context: Checking...</div>
    <div id="model-status">Model: Loading...</div>
    <div id="ar-status">AR Support: Checking...</div>
    <button id="test-button">Test AI Response</button>
    <button id="reset-button">Reset Avatar</button>
</div>

<div id="ar-button-container">
    <button id="ar-button-placeholder">Enter Augmented Reality</button>
</div>

<div id="ar-controls-container" style="position:absolute; bottom:2rem; left:50%; transform:translateX(-50%); z-index:10; display:none; flex-direction:column; align-items:center; gap:0.5rem;">
    <button id="mic-button" class="w-16 h-16 bg-blue-600 hover:bg-blue-700 text-white font-bold p-4 rounded-full transition duration-200 shadow-lg flex justify-center items-center">
        <svg id="mic-icon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M12 1a3 3 0 0 0-3 3v8a3 3 0 0 0 6 0V4a3 3 0 0 0-3-3z"></path><path d="M19 10v2a7 7 0 0 1-14 0v-2"></path><line x1="12" y1="19" x2="12" y2="23"></line></svg>
        <div id="thinking-icon" class="thinking-loader" style="display:none; width:24px; height:24px;"></div>
    </button>
    <div id="mic-level"><div id="mic-level-fill"></div></div>
    <!-- Text input fallback -->
    <div style="display:flex; gap:0.5rem; width:90vw; max-width:520px;">
        <input id="text-input" type="text" placeholder="Type your prompt..." class="flex-1 px-3 py-2 rounded-md bg-gray-800 text-gray-100 border border-gray-600 focus:outline-none focus:ring-2 focus:ring-blue-500" />
        <button id="send-button" class="px-4 py-2 rounded-md bg-green-600 hover:bg-green-700 text-white font-semibold">Send</button>
    </div>
</div>

<script async src="https://unpkg.com/es-module-shims@1.8.0/dist/es-module-shims.js"></script>
<script type="importmap">
{
    "imports": {
        "three": "https://cdn.jsdelivr.net/npm/three@0.160.0/build/three.module.js",
        "three/addons/": "https://cdn.jsdelivr.net/npm/three@0.160.0/examples/jsm/"
    }
}
</script>

<script type="module">
import * as THREE from 'three';
import { GLTFLoader } from 'three/addons/loaders/GLTFLoader.js';
import { OrbitControls } from 'three/addons/controls/OrbitControls.js';
import { ARButton } from 'three/addons/webxr/ARButton.js';

// Backend proxy base URL (host your Node backend on Vercel/Render/Railway/Fly)
// Example: https://your-backend.example.com
const BACKEND_URL = 'https://ar-avatar.vercel.app';

let camera, scene, renderer, controls, model, mixer, clock, jawOpenMorphTargetIndex = null;
let reticle, speechRecognition, isListening=false, isSpeaking=false, isAIThinking=false, currentAudio=null, audioContext, analyser, dataArray;
let hitTestSource=null, hitTestSourceRequested=false, groundPlane=null;
let audioSource, activeGesture=null, initialScale=new THREE.Vector3(), initialPinchDistance=0;

const loadingOverlay=document.getElementById('loading-overlay');
const arButtonContainer=document.getElementById('ar-button-container');
const arInstructions=document.getElementById('ar-instructions');
const statusMessage=document.getElementById('status-message');
const arControlsContainer=document.getElementById('ar-controls-container');
const micButton=document.getElementById('mic-button');
const micIcon=document.getElementById('mic-icon');
const thinkingIcon=document.getElementById('thinking-icon');
const testButton=document.getElementById('test-button');
const resetButton=document.getElementById('reset-button');
const micLevelFill=document.getElementById('mic-level-fill');
const textInput=document.getElementById('text-input');
const sendButton=document.getElementById('send-button');

const apiKeyStatus=document.getElementById('api-key-status');
const speechStatus=document.getElementById('speech-status');
const audioStatus=document.getElementById('audio-status');
const modelStatus=document.getElementById('model-status');
const arStatus=document.getElementById('ar-status');

const defaultAvatarUrl='https://raw.githubusercontent.com/mgb111/ar-avatar/main/avatar.glb';
const aiQueue=[];

init();

function init(){
    // Backend URL check
    if(!BACKEND_URL){
        apiKeyStatus.textContent='Backend: âŒ Missing BACKEND_URL';
        apiKeyStatus.style.color='#ef4444';
    } else { apiKeyStatus.textContent='Backend: âœ… Connected (proxy)'; apiKeyStatus.style.color='#10b981'; }

    scene=new THREE.Scene();
    clock=new THREE.Clock();
    camera=new THREE.PerspectiveCamera(75,window.innerWidth/window.innerHeight,0.1,1000);
    camera.position.set(0,1.6,2.5);

    // Audio context
    try{ 
        audioContext=new (window.AudioContext||window.webkitAudioContext)();
        audioStatus.textContent='Audio Context: âœ… Supported';
        audioStatus.style.color='#10b981';
    } catch(e){
        audioStatus.textContent='Audio Context: âŒ Not Supported';
        audioStatus.style.color='#ef4444';
    }

    // WebXR Support
    if('xr' in navigator){
        navigator.xr.isSessionSupported('immersive-ar').then(supported=>{
            if(supported){ arStatus.textContent='AR Support: âœ… Supported'; arStatus.style.color='#10b981'; }
            else{ arStatus.textContent='AR Support: âŒ Not Supported'; arStatus.style.color='#ef4444'; }
        });
    } else { arStatus.textContent='AR Support: âŒ WebXR Not Available'; arStatus.style.color='#ef4444'; }

    const ambientLight=new THREE.AmbientLight(0xffffff,1.5); scene.add(ambientLight);
    const directionalLight=new THREE.DirectionalLight(0xffffff,2.5); directionalLight.position.set(1,1,1); scene.add(directionalLight);

    renderer=new THREE.WebGLRenderer({ antialias:true, alpha:true });
    renderer.setSize(window.innerWidth,window.innerHeight);
    renderer.setPixelRatio(window.devicePixelRatio);
    renderer.xr.enabled=true;
    document.body.appendChild(renderer.domElement);

    controls=new OrbitControls(camera,renderer.domElement);
    controls.target.set(0,1,0);
    controls.update();

    loadModel(defaultAvatarUrl);
    setupSpeechRecognition();
    setupAR();

    micButton.addEventListener('click',toggleListening);
    testButton.addEventListener('click',()=>queueAI("Hello, can you introduce yourself?"));
    resetButton.addEventListener('click',resetAvatar);
    if(sendButton){
        const sendText=()=>{ const v=textInput?.value?.trim(); if(!v||isSpeaking||isAIThinking) return; queueAI(v); textInput.value=''; };
        sendButton.addEventListener('click',sendText);
        textInput?.addEventListener('keydown',(e)=>{ if(e.key==='Enter'){ e.preventDefault(); sendText(); }});
    }

    window.addEventListener('resize',onWindowResize);
    renderer.domElement.addEventListener('touchstart',onTouchStart,{passive:false});
    renderer.domElement.addEventListener('touchmove',onTouchMove,{passive:false});
    renderer.domElement.addEventListener('touchend',onTouchEnd);

    renderer.setAnimationLoop(animate);
}

// --- Functions --- //

function showStatusMessage(message,isError=true){
    statusMessage.textContent=message;
    statusMessage.style.backgroundColor=isError?'rgba(239,68,68,0.8)':'rgba(34,197,94,0.8)';
    statusMessage.style.display='block';
    setTimeout(()=>{statusMessage.style.display='none';},5000);
}

// --- AR Button --- //
function setupAR(){
    const arButton=ARButton.createButton(renderer,{ requiredFeatures:['hit-test','dom-overlay'], domOverlay:{root:document.body} });
    arButton.id='ar-button';
    arButton.textContent="Enter Augmented Reality";
    arButton.addEventListener('click',()=>{ if(audioContext.state==='suspended') audioContext.resume(); });
    renderer.xr.addEventListener('sessionstart',()=>{
        arButtonContainer.style.display='none';
        arInstructions.style.display='flex';
        controls.enabled=false;
        arControlsContainer.style.display='flex';
    });
    renderer.xr.addEventListener('sessionend',()=>{
        arButtonContainer.style.display='flex';
        arControlsContainer.style.display='none';
        arInstructions.style.display='none';
        if(currentAudio) currentAudio.pause();
        controls.enabled=true;
        if(model){ model.position.set(0,0,0); model.visible=true; }
    });
    arButtonContainer.innerHTML=''; arButtonContainer.appendChild(arButton);

    reticle=new THREE.Mesh(
        new THREE.RingGeometry(0.05,0.07,32).rotateX(-Math.PI/2),
        new THREE.MeshBasicMaterial()
    );
    reticle.matrixAutoUpdate=false;
    reticle.visible=false;
    scene.add(reticle);

    let controller=renderer.xr.getController(0);
    controller.addEventListener('select',onSelect);
    scene.add(controller);
}

// --- Speech Recognition --- //
function setupSpeechRecognition(){
    const SpeechRecognition=window.SpeechRecognition||window.webkitSpeechRecognition;
    if(SpeechRecognition){
        speechRecognition=new SpeechRecognition();
        // Android Chrome works better with interimResults and sometimes continuous
        speechRecognition.continuous=true;
        speechRecognition.lang=navigator.language||'en-US';
        speechRecognition.interimResults=true;
        speechRecognition.maxAlternatives=1;

        speechRecognition.onresult=(event)=>{
            // Build the full transcript including interim results
            let interim=''; let final='';
            for(let i=event.resultIndex;i<event.results.length;i++){
                const res=event.results[i];
                if(res.isFinal) final += res[0].transcript;
                else interim += res[0].transcript;
            }
            if(interim){ speechStatus.textContent=`Speech Recognition: ðŸ“ ${interim}`; speechStatus.style.color='#10b981'; }
            if(final){ queueAI(final.trim()); }
        };
        speechRecognition.onstart=()=>{ isListening=true; speechStatus.textContent='Speech Recognition: ðŸŽ¤ Listening'; speechStatus.style.color='#10b981'; micButton.classList.add('bg-red-600','hover:bg-red-700'); micButton.classList.remove('bg-blue-600','hover:bg-blue-700'); };
        speechRecognition.onend=()=>{ isListening=false; speechStatus.textContent='Speech Recognition: â¹ï¸ Stopped'; speechStatus.style.color='#d1d5db'; micButton.classList.remove('bg-red-600','hover:bg-red-700'); micButton.classList.add('bg-blue-600','hover:bg-blue-700'); };
        speechRecognition.onaudiostart=()=>{ speechStatus.textContent='Speech Recognition: ðŸŽ§ Audio detected'; speechStatus.style.color='#10b981'; };
        speechRecognition.onaudioend=()=>{ /* often fires quickly on Android */ };
        speechRecognition.onspeechstart=()=>{ speechStatus.textContent='Speech Recognition: ðŸ—£ï¸ Speech detected'; speechStatus.style.color='#10b981'; };
        speechRecognition.onspeechend=()=>{ /* recognition will finalize shortly */ };
        // Single auto-retry on no match (some Android builds require a quick restart)
        let didRetryNoMatch=false;
        speechRecognition.onnomatch=()=>{
            speechStatus.textContent='Speech Recognition: ðŸ¤” No match';
            speechStatus.style.color='#fbbf24';
            if(!didRetryNoMatch){
                didRetryNoMatch=true;
                try{ speechRecognition.abort(); }catch{}
                setTimeout(()=>{ try{ speechRecognition.start(); }catch{} }, 200);
            } else {
                showStatusMessage('Did not catch that. Please try again.', false);
            }
        };
        speechRecognition.onerror=(event)=>{
            let hint='';
            if(event.error==='not-allowed' || event.error==='denied') hint='Please allow microphone access in your browser settings.';
            if(event.error==='no-speech') hint='No speech detected. Try speaking closer to the mic.';
            if(event.error==='aborted') hint='Recognition aborted. Tap the mic again.';
            speechStatus.textContent=`Speech Recognition: âŒ ${event.error}`;
            speechStatus.style.color='#ef4444';
            showStatusMessage(`Microphone error: ${event.error}. ${hint}`);
        };
        // Reset retry flag when session ends
        speechRecognition.onend=(()=>{
            const origEnd = speechRecognition.onend;
            return ()=>{
                didRetryNoMatch=false;
                isListening=false; speechStatus.textContent='Speech Recognition: â¹ï¸ Stopped'; speechStatus.style.color='#d1d5db'; micButton.classList.remove('bg-red-600','hover:bg-red-700'); micButton.classList.add('bg-blue-600','hover:bg-blue-700');
                if(typeof origEnd==='function') origEnd();
            };
        })();

        speechStatus.textContent='Speech Recognition: âœ… Supported'; speechStatus.style.color='#10b981';
    } else { speechStatus.textContent='Speech Recognition: âŒ Not Supported'; speechStatus.style.color='#ef4444'; micButton.disabled=true; showStatusMessage('Voice input not supported',false); }
}

function toggleListening(){
    if(isListening||isSpeaking||isAIThinking) return;
    if(currentAudio) currentAudio.pause();
    // SpeechRecognition requires secure context (https or localhost)
    const isSecure = location.protocol==='https:' || location.hostname==='localhost';
    if(!isSecure){ showStatusMessage('Voice input requires HTTPS. Please use a secure URL.'); return; }
    if(navigator.mediaDevices?.getUserMedia){
        navigator.mediaDevices.getUserMedia({audio:true}).then(()=>{
            try{ speechRecognition.abort(); }catch{}
            try{ speechRecognition.start(); }catch{ showStatusMessage('Unable to start speech recognition'); }
        }).catch(()=>{ showStatusMessage('Microphone access denied'); });
    } else if(speechRecognition){ speechRecognition.start(); } else { showStatusMessage('Voice input unavailable'); }
}

// --- AI Queue --- //
function queueAI(prompt){ aiQueue.push(prompt); if(!isAIThinking && !isSpeaking) processAIQueue(); }
async function processAIQueue(){
    if(!aiQueue.length) return;
    const prompt=aiQueue.shift();
    await getAIResponse(prompt);
    processAIQueue();
}

// --- OpenAI API --- //
async function getAIResponse(userPrompt){
    isAIThinking=true; micIcon.style.display='none'; thinkingIcon.style.display='block'; micButton.disabled=true; if(sendButton) sendButton.disabled=true; if(textInput) textInput.disabled=true;

    const systemPrompt=`You are a helpful AR avatar assistant. Be concise and conversational.`;

    try{
        if(!BACKEND_URL){ throw new Error('Backend URL not configured'); }
        const response=await fetch(`${BACKEND_URL}/api/chat`,{
            method:'POST',
            headers:{'Content-Type':'application/json'},
            body:JSON.stringify({ systemPrompt, userPrompt })
        });
        if(!response.ok){
            let detail = '';
            const clone = response.clone();
            try { detail = JSON.stringify(await response.json()); }
            catch { detail = (await clone.text()).slice(0,200); }
            throw new Error(`API error ${response.status}: ${detail}`);
        }
        const data=await response.json();
        const text=data.text||"Sorry, I couldn't generate a response.";
        await generateAndPlaySpeech(text.trim());
    } catch(error){ showStatusMessage(error.message); console.error(error); }
    finally{ isAIThinking=false; micIcon.style.display='block'; thinkingIcon.style.display='none'; micButton.disabled=false; if(sendButton) sendButton.disabled=false; if(textInput) textInput.disabled=false; }
}

// --- TTS + Lip-Sync --- //
async function generateAndPlaySpeech(text){
    if(!text||!model) return;
    isSpeaking=true;

    try{
        if(!BACKEND_URL){ throw new Error('Backend URL not configured'); }
        const response=await fetch(`${BACKEND_URL}/api/tts`,{
            method:'POST',
            headers:{'Content-Type':'application/json'},
            body:JSON.stringify({ text })
        });
        if(!response.ok){
            let detail = '';
            const clone = response.clone();
            try { detail = JSON.stringify(await response.json()); }
            catch { detail = (await clone.text()).slice(0,200); }
            throw new Error(`TTS generation failed (${response.status}): ${detail}`);
        }
        // Clean up any previous playback and nodes
        try{ if(currentAudio){ currentAudio.pause(); currentAudio.src=''; } }catch{}
        try{ if(audioSource){ audioSource.disconnect(); audioSource=null; } }catch{}
        try{ if(analyser){ analyser.disconnect(); analyser=null; } }catch{}

        const blob=await response.blob();
        const audioUrl=URL.createObjectURL(blob);
        const audio=new Audio();
        audio.src = audioUrl;
        audio.preload = 'auto';
        audio.playsInline = true;
        audio.loop=false;
        currentAudio=audio;

        // Build audio graph
        if(audioContext.state==='suspended') { try{ await audioContext.resume(); }catch{} }
        audioSource=audioContext.createMediaElementSource(audio);
        analyser=audioContext.createAnalyser();
        analyser.fftSize=128; // lighter processing to reduce glitches
        dataArray=new Uint8Array(analyser.frequencyBinCount);
        audioSource.connect(analyser).connect(audioContext.destination);

        const startPlayback = async ()=>{
            try{
                await audio.play();
                animateJawSync();
            }catch(e){ console.warn('Playback start failed, trying resume', e); try{ await audioContext.resume(); await audio.play(); }catch(err){ console.error(err); showStatusMessage('Audio playback blocked'); } }
        };
        if(audio.readyState>=3){
            await startPlayback();
        } else {
            audio.addEventListener('canplaythrough', startPlayback, { once:true });
        }

        audio.onended=()=>{
            isSpeaking=false;
            jawOpenMorphTargetIndex!==null && setJaw(0);
            try{ if(audioSource){ audioSource.disconnect(); audioSource=null; } }catch{}
            try{ if(analyser){ analyser.disconnect(); analyser=null; } }catch{}
            try{ URL.revokeObjectURL(audioUrl); }catch{}
        };
    } catch(e){ console.error(e); showStatusMessage('Audio playback error'); isSpeaking=false; }
}

// --- Jaw Lip-Sync --- //
function animateJawSync(){
    if(!analyser || jawOpenMorphTargetIndex===null || !model) return;
    requestAnimationFrame(animateJawSync);
    analyser.getByteFrequencyData(dataArray);
    const avgAmplitude=dataArray.reduce((a,b)=>a+b,0)/dataArray.length/256;
    setJaw(avgAmplitude*1.5); // scale factor
}

function setJaw(value){ if(model && jawOpenMorphTargetIndex!==null) model.morphTargetInfluences[jawOpenMorphTargetIndex]=Math.min(Math.max(value,0),1); }

// --- Model Loading --- //
function loadModel(url){
    const loader=new GLTFLoader();
    loader.load(url, gltf=>{
        model=gltf.scene; scene.add(model); model.position.set(0,0,0); model.visible=true;
        model.traverse(child=>{ if(child.isMesh && child.morphTargetDictionary && child.morphTargetDictionary['jawOpen']!==undefined) jawOpenMorphTargetIndex=child.morphTargetDictionary['jawOpen']; });
        loadingOverlay.style.display='none';
        modelStatus.textContent='Model: âœ… Loaded'; modelStatus.style.color='#10b981';
    },xhr=>{},err=>{ console.error(err); loadingOverlay.style.display='none'; showStatusMessage('Failed to load 3D model'); });
}

// --- AR Placement --- //
function onSelect(){
    if(!reticle.visible) return;
    if(model){ model.position.setFromMatrixPosition(reticle.matrix); model.visible=true; arInstructions.style.display='none'; reticle.visible=false; }
}

// --- Reset Avatar --- //
function resetAvatar(){ if(model){ model.position.set(0,0,0); model.scale.set(1,1,1); model.rotation.set(0,0,0); jawOpenMorphTargetIndex!==null && setJaw(0); reticle.visible=true; } }

// --- Touch Gestures for Scale --- //
let ongoingTouches=[];
function getDistance(touches){ const dx=touches[0].clientX-touches[1].clientX; const dy=touches[0].clientY-touches[1].clientY; return Math.sqrt(dx*dx+dy*dy); }
function onTouchStart(e){ if(e.touches.length===2 && model){ initialScale.copy(model.scale); initialPinchDistance=getDistance(e.touches); } }
function onTouchMove(e){ if(e.touches.length===2 && model){ const newDist=getDistance(e.touches); const scaleFactor=newDist/initialPinchDistance; model.scale.copy(initialScale.clone().multiplyScalar(scaleFactor)); } }
function onTouchEnd(e){ if(e.touches.length<2) initialPinchDistance=0; }

// --- Window Resize --- //
function onWindowResize(){ camera.aspect=window.innerWidth/window.innerHeight; camera.updateProjectionMatrix(); renderer.setSize(window.innerWidth,window.innerHeight); }

// --- Animate Loop --- //
function animate(){ const delta=clock.getDelta(); if(mixer) mixer.update(delta); renderer.render(scene,camera); updateARHitTest(); updateMicLevel(); }

function updateARHitTest(){
    if(renderer.xr.isPresenting && !hitTestSourceRequested){
        const session=renderer.xr.getSession();
        session.requestReferenceSpace('viewer').then(refSpace=>{
            session.requestHitTestSource({space:refSpace}).then(source=>{ hitTestSource=source; });
        });
        session.addEventListener('end',()=>{ hitTestSourceRequested=false; hitTestSource=null; });
        hitTestSourceRequested=true;
    }
    if(hitTestSource && renderer.xr.getSession()){
        const frame=renderer.xr.getFrame();
        const referenceSpace=renderer.xr.getReferenceSpace();
        const hitTestResults=frame.getHitTestResults(hitTestSource);
        if(hitTestResults.length>0){
            const pose=hitTestResults[0].getPose(referenceSpace);
            reticle.visible=true;
            reticle.position.set(pose.transform.position.x,pose.transform.position.y,pose.transform.position.z);
            reticle.updateMatrix();
        } else { reticle.visible=false; }
    }
}

// --- Mic Level --- //
function updateMicLevel(){
    if(analyser && isListening){
        analyser.getByteFrequencyData(dataArray);
        const avg=dataArray.reduce((a,b)=>a+b,0)/dataArray.length;
        micLevelFill.style.width=Math.min((avg/128*100),100)+'%';
    } else { micLevelFill.style.width='0%'; }
}
</script>
</body>
</html>
